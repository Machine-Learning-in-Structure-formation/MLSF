{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training the data filtered by DBscan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deleting Noises and runing the ML model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               id  In_halo  den_rc=0.8  den_rc=1.2  den_rc=1.6  den_rc=2  \\\n",
      "0        194017.0      0.0   -0.000684   -0.020199   -0.011283 -0.012361   \n",
      "1        194067.0      0.0    0.002344   -0.016610   -0.007876 -0.009066   \n",
      "2        194211.0      0.0    0.002344   -0.022891   -0.014311 -0.011973   \n",
      "3        194262.0      0.0   -0.003712   -0.015713   -0.015447 -0.013330   \n",
      "4        194310.0      0.0    0.014457   -0.013021   -0.010526 -0.009648   \n",
      "...           ...      ...         ...         ...         ...       ...   \n",
      "59995  19488712.0      0.0   -0.018854   -0.033658   -0.028695 -0.019338   \n",
      "59996  19488792.0      0.0    0.005372   -0.022891   -0.013176 -0.018950   \n",
      "59997  19488798.0      0.0   -0.027938   -0.016610   -0.012797 -0.013330   \n",
      "59998  19488852.0      0.0   -0.024910   -0.029172   -0.028317 -0.018369   \n",
      "59999  19488874.0      0.0   -0.079418   -0.039939   -0.033995 -0.023020   \n",
      "\n",
      "       den_rc=2.4  den_rc=2.8  den_rc=3.2  den_rc=3.6  den_rc=4  den_rc=4.4  \\\n",
      "0       -0.011563   -0.012744   -0.014075   -0.012357 -0.010883   -0.010872   \n",
      "1       -0.011563   -0.012108   -0.009012   -0.008003 -0.010399   -0.008779   \n",
      "2       -0.008759   -0.007518   -0.010289   -0.010928 -0.010423   -0.010508   \n",
      "3       -0.012124   -0.013662   -0.012702   -0.012058 -0.011029   -0.010563   \n",
      "4       -0.009545   -0.009848   -0.010053   -0.010164 -0.009163   -0.009307   \n",
      "...           ...         ...         ...         ...       ...         ...   \n",
      "59995   -0.016386   -0.014015   -0.011378   -0.011260 -0.010835   -0.010636   \n",
      "59996   -0.013021   -0.011755   -0.011851   -0.009299 -0.009817   -0.010891   \n",
      "59997   -0.016274   -0.015428   -0.012939   -0.012124 -0.011828   -0.010891   \n",
      "59998   -0.019863   -0.017406   -0.016961   -0.016278 -0.013693   -0.011837   \n",
      "59999   -0.018966   -0.015640   -0.015683   -0.013852 -0.013742   -0.012001   \n",
      "\n",
      "       den_rc=4.8       v^2  \n",
      "0       -0.010806  0.155199  \n",
      "1       -0.009334  0.119852  \n",
      "2       -0.010147  0.157102  \n",
      "3       -0.010778  0.145847  \n",
      "4       -0.010820  0.142346  \n",
      "...           ...       ...  \n",
      "59995   -0.010764  0.014207  \n",
      "59996   -0.010358  0.039720  \n",
      "59997   -0.011213  0.050579  \n",
      "59998   -0.011087  0.083200  \n",
      "59999   -0.010904  0.024552  \n",
      "\n",
      "[58508 rows x 14 columns]\n",
      "58508\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "data = all_boxes[all_boxes[:,-2] == 1]\n",
    "feature = np.array(features)\n",
    "good_particles = features[np.isin(feature[:,0], data[:-2])]\n",
    "print(good_particles)\n",
    "print(len(good_particles))\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.22280225 -1.14897467 -0.87305077 ... -1.39949367 -1.46623017\n",
      "  -0.13124614]\n",
      " [-0.12219863 -0.99278868 -0.69706224 ... -1.17951317 -1.30036837\n",
      "  -0.4044187 ]\n",
      " [-0.12219863 -1.26611417 -1.02948501 ... -1.36123619 -1.39198727\n",
      "  -0.11654065]\n",
      " ...\n",
      " [-1.12823484 -0.99278868 -0.95126789 ... -1.40140654 -1.51203962\n",
      "  -0.93977067]\n",
      " [-1.02763122 -1.53943967 -1.75299339 ... -1.50087599 -1.4978229\n",
      "  -0.68766708]\n",
      " [-2.83849639 -2.00799766 -2.0463076  ... -1.51809185 -1.47728763\n",
      "  -1.14091091]]\n",
      "[0. 0. 1. ... 0. 0. 0.]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "[0. 1. 0. ... 0. 0. 1.]\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#Now applying neural network on our good particles\n",
    "#Making the matrices\n",
    "\n",
    "X, y = good_particles.iloc[:,2:].values , good_particles['In_halo'].values\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "print(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2)\n",
    "\n",
    "from keras import utils\n",
    "y_u_test = utils.to_categorical(y_test)\n",
    "y_u_train = utils.to_categorical(y_train)\n",
    "\n",
    "print(y_test)\n",
    "print(y_u_test)\n",
    "print(y_train)\n",
    "print(y_u_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Designing neural network\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import BatchNormalization\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "# Neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(9, input_dim=12, activation='relu'))\n",
    "model.add(Dense(8, activation='tanh'))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "# model.add(Dense(12, activation='relu'))\n",
    "# model.add(Dense(5, activation='relu'))\n",
    "# model.add(Dense(3, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "layer = layers.Dense(\n",
    "    units=64,\n",
    "    kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
    "    bias_initializer='zeros'\n",
    ")\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.1,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.01)\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer = opt , metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46806 samples, validate on 11702 samples\n",
      "Epoch 1/400\n",
      "46806/46806 [==============================] - 1s 17us/step - loss: 0.6397 - accuracy: 0.6982 - val_loss: 0.5901 - val_accuracy: 0.7558\n",
      "Epoch 2/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.5475 - accuracy: 0.7679 - val_loss: 0.5141 - val_accuracy: 0.7768\n",
      "Epoch 3/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4992 - accuracy: 0.7803 - val_loss: 0.4842 - val_accuracy: 0.7871\n",
      "Epoch 4/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4753 - accuracy: 0.7894 - val_loss: 0.4657 - val_accuracy: 0.7920\n",
      "Epoch 5/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4609 - accuracy: 0.7942 - val_loss: 0.4562 - val_accuracy: 0.7961\n",
      "Epoch 6/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4529 - accuracy: 0.7966 - val_loss: 0.4495 - val_accuracy: 0.7974\n",
      "Epoch 7/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4481 - accuracy: 0.7975 - val_loss: 0.4475 - val_accuracy: 0.7966\n",
      "Epoch 8/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4451 - accuracy: 0.7978 - val_loss: 0.4430 - val_accuracy: 0.8001\n",
      "Epoch 9/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4426 - accuracy: 0.7984 - val_loss: 0.4412 - val_accuracy: 0.8007\n",
      "Epoch 10/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4406 - accuracy: 0.7986 - val_loss: 0.4391 - val_accuracy: 0.8006\n",
      "Epoch 11/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4389 - accuracy: 0.7991 - val_loss: 0.4375 - val_accuracy: 0.8015\n",
      "Epoch 12/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4376 - accuracy: 0.7991 - val_loss: 0.4364 - val_accuracy: 0.8009\n",
      "Epoch 13/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4365 - accuracy: 0.7995 - val_loss: 0.4350 - val_accuracy: 0.8029\n",
      "Epoch 14/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4354 - accuracy: 0.8000 - val_loss: 0.4353 - val_accuracy: 0.8013\n",
      "Epoch 15/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4349 - accuracy: 0.7991 - val_loss: 0.4332 - val_accuracy: 0.8032\n",
      "Epoch 16/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4337 - accuracy: 0.7992 - val_loss: 0.4324 - val_accuracy: 0.8035\n",
      "Epoch 17/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4331 - accuracy: 0.7991 - val_loss: 0.4320 - val_accuracy: 0.8043\n",
      "Epoch 18/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4328 - accuracy: 0.7994 - val_loss: 0.4315 - val_accuracy: 0.8045\n",
      "Epoch 19/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4320 - accuracy: 0.7996 - val_loss: 0.4313 - val_accuracy: 0.8035\n",
      "Epoch 20/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4316 - accuracy: 0.7998 - val_loss: 0.4303 - val_accuracy: 0.8047\n",
      "Epoch 21/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4311 - accuracy: 0.7997 - val_loss: 0.4299 - val_accuracy: 0.8045\n",
      "Epoch 22/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4306 - accuracy: 0.7995 - val_loss: 0.4296 - val_accuracy: 0.8047\n",
      "Epoch 23/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4303 - accuracy: 0.8000 - val_loss: 0.4297 - val_accuracy: 0.8029\n",
      "Epoch 24/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4301 - accuracy: 0.7996 - val_loss: 0.4290 - val_accuracy: 0.8052\n",
      "Epoch 25/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4296 - accuracy: 0.8004 - val_loss: 0.4289 - val_accuracy: 0.8046\n",
      "Epoch 26/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4294 - accuracy: 0.7995 - val_loss: 0.4286 - val_accuracy: 0.8043\n",
      "Epoch 27/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4292 - accuracy: 0.8002 - val_loss: 0.4290 - val_accuracy: 0.8033\n",
      "Epoch 28/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4290 - accuracy: 0.7995 - val_loss: 0.4286 - val_accuracy: 0.8040\n",
      "Epoch 29/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4287 - accuracy: 0.8000 - val_loss: 0.4288 - val_accuracy: 0.8032\n",
      "Epoch 30/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4286 - accuracy: 0.8000 - val_loss: 0.4282 - val_accuracy: 0.8043\n",
      "Epoch 31/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4284 - accuracy: 0.8003 - val_loss: 0.4276 - val_accuracy: 0.8046\n",
      "Epoch 32/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4282 - accuracy: 0.8003 - val_loss: 0.4275 - val_accuracy: 0.8041\n",
      "Epoch 33/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4280 - accuracy: 0.8002 - val_loss: 0.4277 - val_accuracy: 0.8045\n",
      "Epoch 34/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4280 - accuracy: 0.8002 - val_loss: 0.4274 - val_accuracy: 0.8038\n",
      "Epoch 35/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4278 - accuracy: 0.8002 - val_loss: 0.4271 - val_accuracy: 0.8041\n",
      "Epoch 36/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4276 - accuracy: 0.8005 - val_loss: 0.4285 - val_accuracy: 0.8019\n",
      "Epoch 37/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4275 - accuracy: 0.8006 - val_loss: 0.4270 - val_accuracy: 0.8037\n",
      "Epoch 38/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4275 - accuracy: 0.7997 - val_loss: 0.4268 - val_accuracy: 0.8045\n",
      "Epoch 39/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4274 - accuracy: 0.8002 - val_loss: 0.4277 - val_accuracy: 0.8041\n",
      "Epoch 40/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4273 - accuracy: 0.7998 - val_loss: 0.4270 - val_accuracy: 0.8041\n",
      "Epoch 41/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4271 - accuracy: 0.8007 - val_loss: 0.4266 - val_accuracy: 0.8035\n",
      "Epoch 42/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4271 - accuracy: 0.7996 - val_loss: 0.4265 - val_accuracy: 0.8033\n",
      "Epoch 43/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4269 - accuracy: 0.7999 - val_loss: 0.4265 - val_accuracy: 0.8041\n",
      "Epoch 44/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4269 - accuracy: 0.7997 - val_loss: 0.4264 - val_accuracy: 0.8036\n",
      "Epoch 45/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4269 - accuracy: 0.7999 - val_loss: 0.4264 - val_accuracy: 0.8037\n",
      "Epoch 46/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4267 - accuracy: 0.7997 - val_loss: 0.4262 - val_accuracy: 0.8041\n",
      "Epoch 47/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4266 - accuracy: 0.7998 - val_loss: 0.4265 - val_accuracy: 0.8033\n",
      "Epoch 48/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4266 - accuracy: 0.7998 - val_loss: 0.4263 - val_accuracy: 0.8045\n",
      "Epoch 49/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4266 - accuracy: 0.7995 - val_loss: 0.4260 - val_accuracy: 0.8038\n",
      "Epoch 50/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4265 - accuracy: 0.8005 - val_loss: 0.4261 - val_accuracy: 0.8042\n",
      "Epoch 51/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4264 - accuracy: 0.7998 - val_loss: 0.4259 - val_accuracy: 0.8037\n",
      "Epoch 52/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4263 - accuracy: 0.8002 - val_loss: 0.4260 - val_accuracy: 0.8041\n",
      "Epoch 53/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4262 - accuracy: 0.8002 - val_loss: 0.4259 - val_accuracy: 0.8038\n",
      "Epoch 54/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4263 - accuracy: 0.8004 - val_loss: 0.4258 - val_accuracy: 0.8034\n",
      "Epoch 55/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4263 - accuracy: 0.7999 - val_loss: 0.4263 - val_accuracy: 0.8027\n",
      "Epoch 56/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4261 - accuracy: 0.7999 - val_loss: 0.4259 - val_accuracy: 0.8041\n",
      "Epoch 57/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4260 - accuracy: 0.8000 - val_loss: 0.4256 - val_accuracy: 0.8036\n",
      "Epoch 58/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4260 - accuracy: 0.7998 - val_loss: 0.4256 - val_accuracy: 0.8034\n",
      "Epoch 59/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4259 - accuracy: 0.8003 - val_loss: 0.4260 - val_accuracy: 0.8049\n",
      "Epoch 60/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4259 - accuracy: 0.8005 - val_loss: 0.4255 - val_accuracy: 0.8035\n",
      "Epoch 61/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4260 - accuracy: 0.8004 - val_loss: 0.4255 - val_accuracy: 0.8035\n",
      "Epoch 62/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4258 - accuracy: 0.8005 - val_loss: 0.4255 - val_accuracy: 0.8035\n",
      "Epoch 63/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4258 - accuracy: 0.8003 - val_loss: 0.4255 - val_accuracy: 0.8037\n",
      "Epoch 64/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4258 - accuracy: 0.8000 - val_loss: 0.4255 - val_accuracy: 0.8040\n",
      "Epoch 65/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4257 - accuracy: 0.7998 - val_loss: 0.4254 - val_accuracy: 0.8040\n",
      "Epoch 66/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4257 - accuracy: 0.8004 - val_loss: 0.4254 - val_accuracy: 0.8038\n",
      "Epoch 67/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4256 - accuracy: 0.8000 - val_loss: 0.4255 - val_accuracy: 0.8035\n",
      "Epoch 68/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4256 - accuracy: 0.8005 - val_loss: 0.4253 - val_accuracy: 0.8035\n",
      "Epoch 69/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4255 - accuracy: 0.8002 - val_loss: 0.4253 - val_accuracy: 0.8034\n",
      "Epoch 70/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4256 - accuracy: 0.8004 - val_loss: 0.4254 - val_accuracy: 0.8036\n",
      "Epoch 71/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4255 - accuracy: 0.8001 - val_loss: 0.4252 - val_accuracy: 0.8037\n",
      "Epoch 72/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4255 - accuracy: 0.8001 - val_loss: 0.4253 - val_accuracy: 0.8041\n",
      "Epoch 73/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4255 - accuracy: 0.7998 - val_loss: 0.4252 - val_accuracy: 0.8034\n",
      "Epoch 74/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4255 - accuracy: 0.8003 - val_loss: 0.4251 - val_accuracy: 0.8031\n",
      "Epoch 75/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4254 - accuracy: 0.8007 - val_loss: 0.4251 - val_accuracy: 0.8030\n",
      "Epoch 76/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4254 - accuracy: 0.8001 - val_loss: 0.4251 - val_accuracy: 0.8029\n",
      "Epoch 77/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4253 - accuracy: 0.8002 - val_loss: 0.4252 - val_accuracy: 0.8042\n",
      "Epoch 78/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4254 - accuracy: 0.7998 - val_loss: 0.4251 - val_accuracy: 0.8036\n",
      "Epoch 79/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4253 - accuracy: 0.8002 - val_loss: 0.4251 - val_accuracy: 0.8039\n",
      "Epoch 80/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4253 - accuracy: 0.8001 - val_loss: 0.4251 - val_accuracy: 0.8042\n",
      "Epoch 81/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4252 - accuracy: 0.7998 - val_loss: 0.4250 - val_accuracy: 0.8033\n",
      "Epoch 82/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4252 - accuracy: 0.8000 - val_loss: 0.4250 - val_accuracy: 0.8031\n",
      "Epoch 83/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4252 - accuracy: 0.7996 - val_loss: 0.4249 - val_accuracy: 0.8028\n",
      "Epoch 84/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4252 - accuracy: 0.8002 - val_loss: 0.4249 - val_accuracy: 0.8034\n",
      "Epoch 85/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4252 - accuracy: 0.8002 - val_loss: 0.4249 - val_accuracy: 0.8031\n",
      "Epoch 86/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4252 - accuracy: 0.8003 - val_loss: 0.4249 - val_accuracy: 0.8035\n",
      "Epoch 87/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4251 - accuracy: 0.8002 - val_loss: 0.4249 - val_accuracy: 0.8029\n",
      "Epoch 88/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4251 - accuracy: 0.8005 - val_loss: 0.4249 - val_accuracy: 0.8038\n",
      "Epoch 89/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4251 - accuracy: 0.8001 - val_loss: 0.4249 - val_accuracy: 0.8037\n",
      "Epoch 90/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4251 - accuracy: 0.8001 - val_loss: 0.4248 - val_accuracy: 0.8030\n",
      "Epoch 91/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4250 - accuracy: 0.8004 - val_loss: 0.4248 - val_accuracy: 0.8034\n",
      "Epoch 92/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4250 - accuracy: 0.8005 - val_loss: 0.4249 - val_accuracy: 0.8044\n",
      "Epoch 93/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4250 - accuracy: 0.8003 - val_loss: 0.4248 - val_accuracy: 0.8027\n",
      "Epoch 94/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4250 - accuracy: 0.7999 - val_loss: 0.4248 - val_accuracy: 0.8031\n",
      "Epoch 95/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4250 - accuracy: 0.8004 - val_loss: 0.4248 - val_accuracy: 0.8029\n",
      "Epoch 96/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4250 - accuracy: 0.8003 - val_loss: 0.4248 - val_accuracy: 0.8035\n",
      "Epoch 97/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4249 - accuracy: 0.8002 - val_loss: 0.4248 - val_accuracy: 0.8041\n",
      "Epoch 98/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4250 - accuracy: 0.8002 - val_loss: 0.4248 - val_accuracy: 0.8034\n",
      "Epoch 99/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4249 - accuracy: 0.8003 - val_loss: 0.4248 - val_accuracy: 0.8032\n",
      "Epoch 100/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4249 - accuracy: 0.8005 - val_loss: 0.4247 - val_accuracy: 0.8035\n",
      "Epoch 101/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4249 - accuracy: 0.8006 - val_loss: 0.4247 - val_accuracy: 0.8032\n",
      "Epoch 102/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4249 - accuracy: 0.8006 - val_loss: 0.4247 - val_accuracy: 0.8029\n",
      "Epoch 103/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4248 - accuracy: 0.8001 - val_loss: 0.4247 - val_accuracy: 0.8039\n",
      "Epoch 104/400\n",
      "46806/46806 [==============================] - ETA: 0s - loss: 0.4226 - accuracy: 0.80 - 0s 5us/step - loss: 0.4248 - accuracy: 0.8000 - val_loss: 0.4247 - val_accuracy: 0.8035\n",
      "Epoch 105/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4248 - accuracy: 0.8000 - val_loss: 0.4247 - val_accuracy: 0.8029\n",
      "Epoch 106/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4248 - accuracy: 0.8004 - val_loss: 0.4247 - val_accuracy: 0.8046\n",
      "Epoch 107/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4248 - accuracy: 0.8004 - val_loss: 0.4247 - val_accuracy: 0.8035\n",
      "Epoch 108/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4248 - accuracy: 0.8006 - val_loss: 0.4247 - val_accuracy: 0.8046\n",
      "Epoch 109/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4247 - accuracy: 0.7999 - val_loss: 0.4249 - val_accuracy: 0.8034\n",
      "Epoch 110/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4248 - accuracy: 0.8003 - val_loss: 0.4246 - val_accuracy: 0.8032\n",
      "Epoch 111/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4248 - accuracy: 0.7998 - val_loss: 0.4246 - val_accuracy: 0.8029\n",
      "Epoch 112/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4248 - accuracy: 0.8003 - val_loss: 0.4246 - val_accuracy: 0.8032\n",
      "Epoch 113/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4247 - accuracy: 0.8002 - val_loss: 0.4246 - val_accuracy: 0.8032\n",
      "Epoch 114/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4247 - accuracy: 0.8003 - val_loss: 0.4247 - val_accuracy: 0.8036\n",
      "Epoch 115/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4248 - accuracy: 0.8001 - val_loss: 0.4246 - val_accuracy: 0.8035\n",
      "Epoch 116/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4247 - accuracy: 0.8001 - val_loss: 0.4246 - val_accuracy: 0.8029\n",
      "Epoch 117/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4247 - accuracy: 0.8005 - val_loss: 0.4246 - val_accuracy: 0.8042\n",
      "Epoch 118/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4247 - accuracy: 0.8004 - val_loss: 0.4246 - val_accuracy: 0.8040\n",
      "Epoch 119/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4247 - accuracy: 0.8004 - val_loss: 0.4246 - val_accuracy: 0.8039\n",
      "Epoch 120/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4247 - accuracy: 0.8001 - val_loss: 0.4246 - val_accuracy: 0.8033\n",
      "Epoch 121/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4247 - accuracy: 0.8002 - val_loss: 0.4245 - val_accuracy: 0.8029\n",
      "Epoch 122/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4247 - accuracy: 0.8006 - val_loss: 0.4245 - val_accuracy: 0.8035\n",
      "Epoch 123/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4247 - accuracy: 0.8004 - val_loss: 0.4245 - val_accuracy: 0.8035\n",
      "Epoch 124/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4247 - accuracy: 0.8008 - val_loss: 0.4245 - val_accuracy: 0.8029\n",
      "Epoch 125/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4246 - accuracy: 0.8001 - val_loss: 0.4245 - val_accuracy: 0.8036\n",
      "Epoch 126/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4246 - accuracy: 0.8005 - val_loss: 0.4245 - val_accuracy: 0.8035\n",
      "Epoch 127/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4247 - accuracy: 0.8005 - val_loss: 0.4245 - val_accuracy: 0.8029\n",
      "Epoch 128/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4246 - accuracy: 0.8005 - val_loss: 0.4245 - val_accuracy: 0.8029\n",
      "Epoch 129/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4246 - accuracy: 0.8006 - val_loss: 0.4245 - val_accuracy: 0.8035\n",
      "Epoch 130/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4246 - accuracy: 0.8000 - val_loss: 0.4245 - val_accuracy: 0.8040\n",
      "Epoch 131/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4246 - accuracy: 0.8005 - val_loss: 0.4245 - val_accuracy: 0.8034\n",
      "Epoch 132/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4246 - accuracy: 0.8008 - val_loss: 0.4245 - val_accuracy: 0.8035\n",
      "Epoch 133/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4246 - accuracy: 0.8005 - val_loss: 0.4245 - val_accuracy: 0.8040\n",
      "Epoch 134/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4246 - accuracy: 0.8005 - val_loss: 0.4245 - val_accuracy: 0.8029\n",
      "Epoch 135/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4246 - accuracy: 0.8006 - val_loss: 0.4245 - val_accuracy: 0.8038\n",
      "Epoch 136/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4246 - accuracy: 0.8003 - val_loss: 0.4245 - val_accuracy: 0.8030\n",
      "Epoch 137/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4246 - accuracy: 0.8005 - val_loss: 0.4245 - val_accuracy: 0.8039\n",
      "Epoch 138/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4246 - accuracy: 0.8004 - val_loss: 0.4245 - val_accuracy: 0.8034\n",
      "Epoch 139/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4246 - accuracy: 0.8000 - val_loss: 0.4245 - val_accuracy: 0.8037\n",
      "Epoch 140/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4246 - accuracy: 0.8007 - val_loss: 0.4245 - val_accuracy: 0.8035\n",
      "Epoch 141/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4246 - accuracy: 0.8003 - val_loss: 0.4245 - val_accuracy: 0.8035\n",
      "Epoch 142/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4246 - accuracy: 0.8005 - val_loss: 0.4244 - val_accuracy: 0.8031\n",
      "Epoch 143/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4245 - accuracy: 0.8003 - val_loss: 0.4245 - val_accuracy: 0.8037\n",
      "Epoch 144/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4245 - accuracy: 0.8005 - val_loss: 0.4244 - val_accuracy: 0.8039\n",
      "Epoch 145/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4245 - accuracy: 0.8002 - val_loss: 0.4244 - val_accuracy: 0.8035\n",
      "Epoch 146/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4245 - accuracy: 0.8005 - val_loss: 0.4244 - val_accuracy: 0.8039\n",
      "Epoch 147/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4245 - accuracy: 0.8003 - val_loss: 0.4244 - val_accuracy: 0.8033\n",
      "Epoch 148/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4245 - accuracy: 0.8002 - val_loss: 0.4244 - val_accuracy: 0.8038\n",
      "Epoch 149/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4245 - accuracy: 0.8005 - val_loss: 0.4244 - val_accuracy: 0.8034\n",
      "Epoch 150/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4245 - accuracy: 0.8005 - val_loss: 0.4244 - val_accuracy: 0.8037\n",
      "Epoch 151/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4245 - accuracy: 0.8004 - val_loss: 0.4244 - val_accuracy: 0.8039\n",
      "Epoch 152/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4245 - accuracy: 0.8005 - val_loss: 0.4244 - val_accuracy: 0.8037\n",
      "Epoch 153/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4245 - accuracy: 0.8004 - val_loss: 0.4244 - val_accuracy: 0.8035\n",
      "Epoch 154/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4245 - accuracy: 0.8004 - val_loss: 0.4244 - val_accuracy: 0.8037\n",
      "Epoch 155/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4245 - accuracy: 0.8006 - val_loss: 0.4244 - val_accuracy: 0.8031\n",
      "Epoch 156/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4245 - accuracy: 0.8002 - val_loss: 0.4244 - val_accuracy: 0.8032\n",
      "Epoch 157/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4245 - accuracy: 0.8004 - val_loss: 0.4244 - val_accuracy: 0.8033\n",
      "Epoch 158/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4245 - accuracy: 0.8006 - val_loss: 0.4244 - val_accuracy: 0.8035\n",
      "Epoch 159/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4245 - accuracy: 0.8002 - val_loss: 0.4244 - val_accuracy: 0.8040\n",
      "Epoch 160/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4245 - accuracy: 0.8002 - val_loss: 0.4244 - val_accuracy: 0.8037\n",
      "Epoch 161/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4245 - accuracy: 0.8003 - val_loss: 0.4244 - val_accuracy: 0.8033\n",
      "Epoch 162/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4245 - accuracy: 0.8008 - val_loss: 0.4244 - val_accuracy: 0.8032\n",
      "Epoch 163/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4245 - accuracy: 0.8001 - val_loss: 0.4244 - val_accuracy: 0.8032\n",
      "Epoch 164/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4245 - accuracy: 0.8003 - val_loss: 0.4244 - val_accuracy: 0.8032\n",
      "Epoch 165/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4245 - accuracy: 0.8001 - val_loss: 0.4244 - val_accuracy: 0.8032\n",
      "Epoch 166/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4245 - accuracy: 0.8004 - val_loss: 0.4244 - val_accuracy: 0.8032\n",
      "Epoch 167/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4245 - accuracy: 0.8004 - val_loss: 0.4244 - val_accuracy: 0.8033\n",
      "Epoch 168/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8005 - val_loss: 0.4244 - val_accuracy: 0.8033\n",
      "Epoch 169/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8004 - val_loss: 0.4244 - val_accuracy: 0.8032\n",
      "Epoch 170/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8005 - val_loss: 0.4244 - val_accuracy: 0.8033\n",
      "Epoch 171/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8003 - val_loss: 0.4244 - val_accuracy: 0.8032\n",
      "Epoch 172/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8005 - val_loss: 0.4244 - val_accuracy: 0.8032\n",
      "Epoch 173/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4244 - accuracy: 0.8005 - val_loss: 0.4244 - val_accuracy: 0.8032\n",
      "Epoch 174/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8001 - val_loss: 0.4244 - val_accuracy: 0.8033\n",
      "Epoch 175/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8003 - val_loss: 0.4244 - val_accuracy: 0.8033\n",
      "Epoch 176/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8005 - val_loss: 0.4244 - val_accuracy: 0.8035\n",
      "Epoch 177/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8002 - val_loss: 0.4244 - val_accuracy: 0.8034\n",
      "Epoch 178/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8008 - val_loss: 0.4244 - val_accuracy: 0.8034\n",
      "Epoch 179/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4244 - accuracy: 0.8001 - val_loss: 0.4244 - val_accuracy: 0.8032\n",
      "Epoch 180/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4244 - accuracy: 0.8003 - val_loss: 0.4244 - val_accuracy: 0.8033\n",
      "Epoch 181/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8034\n",
      "Epoch 182/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8003 - val_loss: 0.4244 - val_accuracy: 0.8033\n",
      "Epoch 183/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8006 - val_loss: 0.4244 - val_accuracy: 0.8032\n",
      "Epoch 184/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8035\n",
      "Epoch 185/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8004 - val_loss: 0.4243 - val_accuracy: 0.8034\n",
      "Epoch 186/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8002 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 187/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8004 - val_loss: 0.4243 - val_accuracy: 0.8032\n",
      "Epoch 188/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8033\n",
      "Epoch 189/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4244 - accuracy: 0.8003 - val_loss: 0.4243 - val_accuracy: 0.8032\n",
      "Epoch 190/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4244 - accuracy: 0.8003 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 191/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8003 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 192/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8004 - val_loss: 0.4243 - val_accuracy: 0.8032\n",
      "Epoch 193/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4244 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8035\n",
      "Epoch 194/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4244 - accuracy: 0.8004 - val_loss: 0.4243 - val_accuracy: 0.8035\n",
      "Epoch 195/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8004 - val_loss: 0.4243 - val_accuracy: 0.8033\n",
      "Epoch 196/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8035\n",
      "Epoch 197/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8006 - val_loss: 0.4243 - val_accuracy: 0.8034\n",
      "Epoch 198/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8004 - val_loss: 0.4243 - val_accuracy: 0.8035\n",
      "Epoch 199/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8003 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 200/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4244 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8032\n",
      "Epoch 201/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4244 - accuracy: 0.8004 - val_loss: 0.4243 - val_accuracy: 0.8032\n",
      "Epoch 202/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8035\n",
      "Epoch 203/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8035\n",
      "Epoch 204/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4244 - accuracy: 0.8004 - val_loss: 0.4243 - val_accuracy: 0.8034\n",
      "Epoch 205/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4244 - accuracy: 0.8004 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 206/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8032\n",
      "Epoch 207/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8002 - val_loss: 0.4243 - val_accuracy: 0.8032\n",
      "Epoch 208/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8004 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 209/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8004 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 210/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4244 - accuracy: 0.8004 - val_loss: 0.4243 - val_accuracy: 0.8034\n",
      "Epoch 211/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8034\n",
      "Epoch 212/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8030\n",
      "Epoch 213/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8004 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 214/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8033\n",
      "Epoch 215/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8003 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 216/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8006 - val_loss: 0.4243 - val_accuracy: 0.8034\n",
      "Epoch 217/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8004 - val_loss: 0.4243 - val_accuracy: 0.8034\n",
      "Epoch 218/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8006 - val_loss: 0.4243 - val_accuracy: 0.8033\n",
      "Epoch 219/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8003 - val_loss: 0.4243 - val_accuracy: 0.8034\n",
      "Epoch 220/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8006 - val_loss: 0.4243 - val_accuracy: 0.8034\n",
      "Epoch 221/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8004 - val_loss: 0.4243 - val_accuracy: 0.8034\n",
      "Epoch 222/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8006 - val_loss: 0.4243 - val_accuracy: 0.8035\n",
      "Epoch 223/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4244 - accuracy: 0.8004 - val_loss: 0.4243 - val_accuracy: 0.8034\n",
      "Epoch 224/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8004 - val_loss: 0.4243 - val_accuracy: 0.8034\n",
      "Epoch 225/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8003 - val_loss: 0.4243 - val_accuracy: 0.8034\n",
      "Epoch 226/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8033\n",
      "Epoch 227/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8006 - val_loss: 0.4243 - val_accuracy: 0.8033\n",
      "Epoch 228/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4244 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8034\n",
      "Epoch 229/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4244 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8034\n",
      "Epoch 230/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4244 - accuracy: 0.8004 - val_loss: 0.4243 - val_accuracy: 0.8033\n",
      "Epoch 231/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8033\n",
      "Epoch 232/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8003 - val_loss: 0.4243 - val_accuracy: 0.8033\n",
      "Epoch 233/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8033\n",
      "Epoch 234/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8004 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 235/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4244 - accuracy: 0.8004 - val_loss: 0.4243 - val_accuracy: 0.8033\n",
      "Epoch 236/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8006 - val_loss: 0.4243 - val_accuracy: 0.8032\n",
      "Epoch 237/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8004 - val_loss: 0.4243 - val_accuracy: 0.8032\n",
      "Epoch 238/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 239/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 240/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4244 - accuracy: 0.8006 - val_loss: 0.4243 - val_accuracy: 0.8034\n",
      "Epoch 241/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4244 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 242/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8004 - val_loss: 0.4243 - val_accuracy: 0.8034\n",
      "Epoch 243/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4244 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 244/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8004 - val_loss: 0.4243 - val_accuracy: 0.8034\n",
      "Epoch 245/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8004 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 246/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8004 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 247/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8004 - val_loss: 0.4243 - val_accuracy: 0.8034\n",
      "Epoch 248/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8033\n",
      "Epoch 249/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8004 - val_loss: 0.4243 - val_accuracy: 0.8033\n",
      "Epoch 250/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8033\n",
      "Epoch 251/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8004 - val_loss: 0.4243 - val_accuracy: 0.8033\n",
      "Epoch 252/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8033\n",
      "Epoch 253/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8033\n",
      "Epoch 254/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8032\n",
      "Epoch 255/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8033\n",
      "Epoch 256/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8004 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 257/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 258/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 259/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 260/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 261/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8006 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 262/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 263/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 264/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 265/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8004 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 266/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8032\n",
      "Epoch 267/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8032\n",
      "Epoch 268/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 269/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 270/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 271/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8032\n",
      "Epoch 272/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8004 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 273/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 274/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 275/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 276/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 277/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8032\n",
      "Epoch 278/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8032\n",
      "Epoch 279/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8032\n",
      "Epoch 280/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8032\n",
      "Epoch 281/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8032\n",
      "Epoch 282/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8032\n",
      "Epoch 283/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8032\n",
      "Epoch 284/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8032\n",
      "Epoch 285/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8032\n",
      "Epoch 286/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 287/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8032\n",
      "Epoch 288/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8032\n",
      "Epoch 289/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8032\n",
      "Epoch 290/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8032\n",
      "Epoch 291/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8032\n",
      "Epoch 292/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8004 - val_loss: 0.4243 - val_accuracy: 0.8032\n",
      "Epoch 293/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8032\n",
      "Epoch 294/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8032\n",
      "Epoch 295/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8032\n",
      "Epoch 296/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 297/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 298/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 299/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 300/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 301/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 302/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 303/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 304/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 305/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 306/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 307/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 308/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 309/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 310/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 311/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 312/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 313/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 314/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 315/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 316/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 317/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 318/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 319/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 320/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 321/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 322/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8006 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 323/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 324/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 325/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 326/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 327/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 328/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 329/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 330/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 331/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 332/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 333/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 334/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 335/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 336/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 337/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 338/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 339/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 340/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 341/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 342/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 343/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 344/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 345/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 346/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 347/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 348/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 349/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 350/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 351/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 352/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 353/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 354/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 355/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 356/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 357/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 358/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 359/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 360/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 361/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 362/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 363/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 364/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 365/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 366/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 367/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 368/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 369/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 370/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 371/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 372/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 373/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 374/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 375/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 376/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 377/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 378/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 379/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 380/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 381/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 382/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 383/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 384/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 385/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 386/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 387/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 388/400\n",
      "46806/46806 [==============================] - 0s 7us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 389/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 390/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 391/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 392/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 393/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 394/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 395/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 396/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 397/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 398/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 399/400\n",
      "46806/46806 [==============================] - 0s 5us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n",
      "Epoch 400/400\n",
      "46806/46806 [==============================] - 0s 6us/step - loss: 0.4243 - accuracy: 0.8005 - val_loss: 0.4243 - val_accuracy: 0.8031\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_u_train,validation_data = (X_test,y_u_test), epochs=400, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 0 0]\n",
      "[0. 0. 1. ... 0. 0. 0.]\n",
      "[[0.9445162  0.05548387]\n",
      " [0.96983814 0.03016183]\n",
      " [0.11038145 0.8896185 ]\n",
      " ...\n",
      " [0.9700566  0.02994346]\n",
      " [0.93795794 0.0620421 ]\n",
      " [0.9700566  0.02994346]]\n",
      "Accuracy is: 80.31105793881387\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test)\n",
    "#Converting predictions to label\n",
    "print(y_pred)\n",
    "print(y_test)\n",
    "\n",
    "y_u_pred = model.predict(X_test)\n",
    "print(y_u_pred)\n",
    "pred = list()\n",
    "for i in range(len(y_pred)):\n",
    "     pred.append(np.argmax(y_u_pred[i]))\n",
    "#Converting one hot encoded test label to label\n",
    "test = list()\n",
    "for i in range(len(y_test)):\n",
    "    test.append(np.argmax(y_u_test[i]))\n",
    "    \n",
    "from sklearn.metrics import accuracy_score\n",
    "a = accuracy_score(pred,test)\n",
    "print('Accuracy is:', a*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-1.1530716,  0.3306176],\n",
      "       [-0.9819671,  1.3078482],\n",
      "       [ 0.9889726, -0.9914299]], dtype=float32), array([ 1.7390218, -1.7390219], dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "print(weights)  \n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png', show_shapes=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(history.history)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss']) \n",
    "plt.title('Model loss') \n",
    "plt.ylabel('Loss') \n",
    "plt.xlabel('Epoch') \n",
    "plt.legend(['Train', 'Test'], loc='upper left') \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11702/11702 [==============================] - 0s 20us/step\n",
      "[0.4242868794119067, 0.8031105995178223]\n",
      "[0 0 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_u_test,verbose=1)\n",
    "\n",
    "print(score)\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created `%t` as an alias for `%timeit`.\n",
      "Created `%%t` as an alias for `%%timeit`.\n",
      "1min 3s ± 1.2 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "11702\n",
      "5751\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import timeit\n",
    "%alias_magic t timeit\n",
    "\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 1000, min_samples_split = 10, min_samples_leaf = 4, \n",
    "                                    max_features = 'sqrt', max_depth = 10, bootstrap = True, random_state=0)\n",
    "\n",
    "%t classifier.fit(X_train , y_train)\n",
    "\n",
    "#Testing the classification on the test sample\n",
    "Y_predict_rf = classifier.predict(X_test)\n",
    "\n",
    "print(len(y_test))\n",
    "print(len(Y_predict_rf[Y_predict_rf == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.80      0.81      6092\n",
      "         1.0       0.79      0.81      0.80      5610\n",
      "\n",
      "    accuracy                           0.81     11702\n",
      "   macro avg       0.81      0.81      0.81     11702\n",
      "weighted avg       0.81      0.81      0.81     11702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "clf_report_rf = classification_report(y_test, Y_predict_rf)\n",
    "print(clf_report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 80.31105793881387\n"
     ]
    }
   ],
   "source": [
    "a = accuracy_score(pred,test)\n",
    "#b = accuracy_score(pred,train)\n",
    "print('Accuracy is:', a*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  608   609   610 ... 86536 86537 86551]\n",
      "[2789219. 2789220. 2789221. ... 3041518. 3041519. 3041533.]\n"
     ]
    }
   ],
   "source": [
    "print(clustering.core_sample_indices_)\n",
    "cm_ids = box[i][clustering.core_sample_indices_, -2]\n",
    "print(cm_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runing ML models only on CMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25667\n",
      "               id  In_halo  den_rc=0.8  den_rc=1.2  den_rc=1.6  den_rc=2  \\\n",
      "25       196585.0      0.0   -0.033995   -0.004049   -0.010904 -0.014881   \n",
      "26       196613.0      0.0   -0.000684   -0.008535   -0.014690 -0.006547   \n",
      "27       196699.0      0.0    0.002344   -0.002254   -0.007498 -0.006353   \n",
      "28       196735.0      0.0    0.011429    0.004924   -0.005227 -0.005578   \n",
      "29       196777.0      0.0   -0.012797    0.000437   -0.013933 -0.009648   \n",
      "...           ...      ...         ...         ...         ...       ...   \n",
      "59979  19485869.0      0.0    0.014457   -0.009432   -0.007119 -0.008485   \n",
      "59980  19485989.0      0.0    0.008400   -0.009432   -0.003712 -0.005384   \n",
      "59981  19486075.0      0.0   -0.009769   -0.017508   -0.002955 -0.001508   \n",
      "59982  19486253.0      0.0   -0.055192   -0.021994   -0.015068 -0.008873   \n",
      "59983  19486349.0      1.0   -0.046108   -0.030967   -0.018475 -0.011198   \n",
      "\n",
      "       den_rc=2.4  den_rc=2.8  den_rc=3.2  den_rc=3.6  den_rc=4  den_rc=4.4  \\\n",
      "25      -0.013470   -0.011755   -0.012750   -0.010596 -0.009115   -0.006959   \n",
      "26      -0.009993   -0.007306   -0.008633   -0.009466 -0.008170   -0.006304   \n",
      "27      -0.007526   -0.008789   -0.010053   -0.010130 -0.009139   -0.007833   \n",
      "28      -0.010218   -0.011332   -0.011851   -0.011028 -0.010689   -0.008779   \n",
      "29      -0.010105   -0.013450   -0.012986   -0.013553 -0.011513   -0.009089   \n",
      "...           ...         ...         ...         ...       ...         ...   \n",
      "59979   -0.005731   -0.004481   -0.003807   -0.001989 -0.003688   -0.004029   \n",
      "59980   -0.003039   -0.001020   -0.000590    0.000105  0.000115   -0.001553   \n",
      "59981   -0.001021   -0.002150   -0.002151   -0.001291 -0.001532   -0.001954   \n",
      "59982   -0.011788   -0.009142   -0.007119   -0.007538 -0.007589   -0.008834   \n",
      "59983   -0.006180   -0.007447   -0.008066   -0.007771 -0.006159   -0.006304   \n",
      "\n",
      "       den_rc=4.8       v^2  \n",
      "25      -0.007259  0.142762  \n",
      "26      -0.005745  0.133271  \n",
      "27      -0.007442  0.157407  \n",
      "28      -0.007918  0.182657  \n",
      "29      -0.008774  0.122345  \n",
      "...           ...       ...  \n",
      "59979   -0.005044  0.065847  \n",
      "59980   -0.003082  0.129207  \n",
      "59981   -0.004105  0.162103  \n",
      "59982   -0.009012  0.040876  \n",
      "59983   -0.006474  0.216528  \n",
      "\n",
      "[25667 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "peaks = features[np.isin(feature[:,0], cm_ids)]\n",
    "print(len(peaks))\n",
    "print(peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.50857837 -0.61602172 -1.06219531 ... -1.11460413 -1.18167668\n",
      "  -0.19068121]\n",
      " [-0.34980956 -0.82557674 -1.27333907 ... -1.0425705  -1.00454084\n",
      "  -0.26601625]\n",
      " [-0.24446694 -0.53219971 -0.87216594 ... -1.21064897 -1.20299859\n",
      "  -0.0744356 ]\n",
      " ...\n",
      " [-0.66583742 -1.24468678 -0.61879343 ... -0.56434724 -0.81264369\n",
      "  -0.03716033]\n",
      " [-2.2459767  -1.45424181 -1.29445344 ... -1.32070035 -1.38669501\n",
      "  -0.99939799]\n",
      " [-1.92994884 -1.87335185 -1.48448282 ... -1.0425705  -1.08982847\n",
      "   0.39484376]]\n",
      "[0. 0. 0. ... 0. 1. 0.]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "X1, y1 = peaks.iloc[:,2:].values , peaks['In_halo'].values\n",
    "\n",
    "X1 = sc.fit_transform(X1)\n",
    "print(X1)\n",
    "\n",
    "X_train1,X_test1,y_train1,y_test1 = train_test_split(X1,y1,test_size = 0.2)\n",
    "\n",
    "y_u_test1 = utils.to_categorical(y_test1)\n",
    "y_u_train1 = utils.to_categorical(y_train1)\n",
    "\n",
    "print(y_test1)\n",
    "print(y_u_test1)\n",
    "print(y_train1)\n",
    "print(y_u_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20533 samples, validate on 5134 samples\n",
      "Epoch 1/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7974 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 2/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7974 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 3/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7974 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 4/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7974 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 5/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7974 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 6/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7974 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 7/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7974 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 8/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7974 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 9/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7974 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 10/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7974 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 11/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7974 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 12/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7974 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 13/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7974 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 14/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7974 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 15/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7974 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 16/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 17/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 18/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 19/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 20/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 21/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 22/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 23/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 24/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 25/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 26/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 27/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 28/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 29/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 30/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 31/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 32/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 33/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 34/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 35/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 36/1000\n",
      "20533/20533 [==============================] - ETA: 0s - loss: 0.4363 - accuracy: 0.79 - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 37/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 38/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 39/1000\n",
      "20533/20533 [==============================] - ETA: 0s - loss: 0.4320 - accuracy: 0.79 - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 40/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 41/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 42/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 43/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 44/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 45/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 46/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 47/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 48/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 49/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 50/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 51/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 52/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 53/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 54/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 55/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 56/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 57/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 58/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 59/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 60/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 61/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 62/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 63/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 64/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 65/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 66/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 67/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 68/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 69/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 70/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 71/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 72/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 73/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 74/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 75/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 76/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 77/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 78/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 79/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 80/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 81/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 82/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 83/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 84/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 85/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 86/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 87/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 88/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 89/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 90/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 91/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 92/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 93/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 94/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 95/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 96/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 97/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 98/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 99/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 100/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 101/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 102/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 103/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 104/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 105/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 106/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 107/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 108/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 109/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 110/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 111/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 112/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 113/1000\n",
      "20533/20533 [==============================] - 0s 8us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 114/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 115/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 116/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 117/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 118/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 119/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 120/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 121/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 122/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 123/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 124/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 125/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 126/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 127/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 128/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 129/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 130/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 131/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 132/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 133/1000\n",
      "20533/20533 [==============================] - ETA: 0s - loss: 0.4291 - accuracy: 0.80 - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 134/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 135/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 136/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 137/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 138/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 139/1000\n",
      "20533/20533 [==============================] - ETA: 0s - loss: 0.4330 - accuracy: 0.79 - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 140/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 141/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 142/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 143/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 144/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 145/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 146/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 147/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 148/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 149/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8023\n",
      "Epoch 150/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 151/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 152/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 153/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 154/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 155/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 156/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 157/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 158/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 159/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 160/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 161/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 162/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 163/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 164/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 165/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 166/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 167/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 168/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 169/1000\n",
      "20533/20533 [==============================] - ETA: 0s - loss: 0.4291 - accuracy: 0.79 - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 170/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 171/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 172/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 173/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 174/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 175/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 176/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 177/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 178/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 179/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 180/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 181/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 182/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 183/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 184/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 185/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 186/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 187/1000\n",
      "20533/20533 [==============================] - ETA: 0s - loss: 0.4315 - accuracy: 0.79 - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 188/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 189/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 190/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 191/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 192/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 193/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 194/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 195/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 196/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 197/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 198/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 199/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 200/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 201/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 202/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 203/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 204/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 205/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 206/1000\n",
      "20533/20533 [==============================] - ETA: 0s - loss: 0.4316 - accuracy: 0.79 - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 207/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 208/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 209/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 210/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 211/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 212/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 213/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 214/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 215/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 216/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 217/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 218/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 219/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 220/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 221/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 222/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 223/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 224/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 225/1000\n",
      "20533/20533 [==============================] - ETA: 0s - loss: 0.4376 - accuracy: 0.79 - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 226/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 227/1000\n",
      "20533/20533 [==============================] - ETA: 0s - loss: 0.4313 - accuracy: 0.80 - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 228/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 229/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 230/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 231/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 232/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 233/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 234/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 235/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 236/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 237/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 238/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 239/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 240/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 241/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 242/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 243/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 244/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 245/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 246/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 247/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 248/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 249/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 250/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 251/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 252/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 253/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 254/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 255/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 256/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 257/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 258/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 259/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 260/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 261/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 262/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 263/1000\n",
      "20533/20533 [==============================] - ETA: 0s - loss: 0.4367 - accuracy: 0.79 - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 264/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 265/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 266/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 267/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 268/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 269/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 270/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 271/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 272/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 273/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 274/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 275/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 276/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 277/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 278/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 279/1000\n",
      "20533/20533 [==============================] - 0s 8us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 280/1000\n",
      "20533/20533 [==============================] - 0s 8us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 281/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 282/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 283/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 284/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 285/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 286/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 287/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 288/1000\n",
      "20533/20533 [==============================] - 0s 8us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 289/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 290/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 291/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 292/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 293/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 294/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 295/1000\n",
      "20533/20533 [==============================] - ETA: 0s - loss: 0.4325 - accuracy: 0.79 - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 296/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 297/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 298/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 299/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 300/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 301/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 302/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 303/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 304/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 305/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 306/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 307/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 308/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 309/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 310/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 311/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 312/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 313/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 314/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 315/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 316/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 317/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 318/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 319/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 320/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 321/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 322/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 323/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 324/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 325/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 326/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 327/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 328/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 329/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 330/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 331/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 332/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 333/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 334/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 335/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 336/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 337/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 338/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 339/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 340/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 341/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 342/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 343/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 344/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 345/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 346/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 347/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 348/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 349/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 350/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 351/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 352/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 353/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 354/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 355/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 356/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 357/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 358/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 359/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 360/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 361/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 362/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 363/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 364/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 365/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 366/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 367/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 368/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 369/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 370/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 371/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 372/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 373/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 374/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 375/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 376/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 377/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 378/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 379/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 380/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 382/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 383/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 384/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 385/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 386/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 387/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 388/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 389/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 390/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 391/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 392/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 393/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 394/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 395/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 396/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 397/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 398/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 399/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 400/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 401/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 402/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 403/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 404/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 405/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 406/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 407/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 408/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 409/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 410/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 411/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 412/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 413/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 414/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 415/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 416/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 417/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 418/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 419/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 420/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 421/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 422/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 423/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 424/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 425/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 426/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 427/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 428/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 429/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 430/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 431/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 432/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 433/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 434/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 435/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 436/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 437/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 438/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 439/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 440/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 441/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 442/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 443/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 444/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 445/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 446/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 447/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 448/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 449/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 450/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 451/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 452/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 453/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 454/1000\n",
      "20533/20533 [==============================] - ETA: 0s - loss: 0.4350 - accuracy: 0.79 - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 455/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 456/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 457/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 458/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 459/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 460/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 461/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 462/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 463/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 464/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 465/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 466/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 467/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 468/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 469/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 470/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 471/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 472/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 473/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 474/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 475/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 476/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 477/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 478/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 479/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 480/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 481/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 482/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 483/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 484/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 485/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 486/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 487/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 488/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 489/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 490/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 491/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 492/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 493/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 494/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 495/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 496/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 497/1000\n",
      "20533/20533 [==============================] - 0s 8us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 498/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 499/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 500/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 501/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 502/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 503/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 504/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 505/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 506/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 507/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 508/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 509/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 510/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 511/1000\n",
      "20533/20533 [==============================] - 0s 8us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 512/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 513/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 514/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 515/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 516/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 517/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 518/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 519/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 520/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 521/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 522/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 523/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 524/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 525/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 526/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 527/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 528/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 529/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 530/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 531/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 532/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 533/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 534/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 535/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 536/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 537/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 538/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 539/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 540/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 541/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 542/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 543/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 544/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 545/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 546/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 547/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 548/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 549/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 550/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 551/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 552/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 553/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 554/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 555/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 556/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 557/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 558/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 559/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 560/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 561/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 562/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 563/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 564/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 565/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 566/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 567/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 568/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 569/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 570/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 571/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 572/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 573/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 574/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 575/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 576/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 577/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 578/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 579/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 580/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 581/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 582/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 583/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 584/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 585/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 586/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 587/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 588/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 589/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 590/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 591/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 592/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 593/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 594/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 595/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 596/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 597/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 598/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 599/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 600/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 601/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 602/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 603/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 604/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 605/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 606/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 607/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 608/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 609/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 610/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 611/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 612/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 613/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 614/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 615/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 616/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 617/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 618/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 619/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 620/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 621/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 622/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 623/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 624/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 625/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 626/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 627/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 628/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 629/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 630/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 631/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 632/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 633/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 634/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 635/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 636/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 637/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 638/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 639/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 640/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 641/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 642/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 643/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 644/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 645/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 646/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 647/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 648/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 649/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 650/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 651/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 652/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 653/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 654/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 655/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 656/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 657/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 658/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 659/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 660/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 661/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 662/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 663/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 664/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 665/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 666/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 667/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 668/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 669/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 670/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 671/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 672/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 673/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 674/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 675/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 676/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 677/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 678/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 679/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 680/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 681/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 682/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 683/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 684/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 685/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 686/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 687/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 688/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 689/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 690/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 691/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 692/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 693/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 694/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 695/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 696/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 697/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 698/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 699/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 700/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 701/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 702/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 703/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 704/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 705/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 706/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 707/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 708/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 709/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 710/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 711/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 712/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 713/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 714/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 715/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 716/1000\n",
      "20533/20533 [==============================] - 0s 8us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 717/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 718/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 719/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 720/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 721/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 722/1000\n",
      "20533/20533 [==============================] - 0s 8us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 723/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 724/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 725/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 726/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 727/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 728/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 729/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 730/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 731/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 732/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 733/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 734/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 735/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 736/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 737/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 738/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 739/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 740/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 741/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 742/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 743/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 744/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 745/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 746/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 747/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 748/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 749/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 750/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 751/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 752/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 753/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 754/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 755/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 756/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 757/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 758/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 759/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 760/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 761/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 762/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 763/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 764/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 765/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 766/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 767/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 768/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 769/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 770/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 771/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 772/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 773/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 774/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 775/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 776/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 777/1000\n",
      "20533/20533 [==============================] - ETA: 0s - loss: 0.4294 - accuracy: 0.80 - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 778/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 779/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 780/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 781/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 782/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 783/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 784/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 785/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 786/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 787/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 788/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 789/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 790/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 791/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 792/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 793/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 794/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 795/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 796/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 797/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 798/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 799/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 800/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 801/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 802/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 803/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 804/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 805/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 806/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 807/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 808/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 809/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 810/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 811/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 812/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 813/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 814/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 815/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 816/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 817/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 818/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 819/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 820/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 821/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 822/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 823/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 824/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 825/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 826/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 827/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 828/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 829/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 830/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 831/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 832/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 833/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 834/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 835/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 836/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 837/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 838/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 839/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 840/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 841/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 842/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 843/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 844/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 845/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 846/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 847/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 848/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 849/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 850/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 851/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 852/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 853/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 854/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 855/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 856/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 857/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 858/1000\n",
      "20533/20533 [==============================] - 0s 8us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 859/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 860/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 861/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 862/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 863/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 864/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 865/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 866/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 867/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 868/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 869/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 870/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 871/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 872/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 873/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 874/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 875/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 876/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 877/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 878/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 879/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 880/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 881/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 882/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 883/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 884/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 885/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 886/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 887/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 888/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 889/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 890/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 891/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 892/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 893/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 894/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 895/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 896/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 897/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 898/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 899/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 900/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 901/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 902/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 903/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 904/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 905/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 906/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 907/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 908/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 909/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 910/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 911/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 912/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 913/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 914/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 915/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 916/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 917/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 918/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 919/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 920/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 921/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 922/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 923/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 924/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 925/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 926/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 927/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 928/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 929/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 930/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 931/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 932/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 933/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 934/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 935/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 936/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 937/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 938/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 939/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 940/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 941/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 942/1000\n",
      "20533/20533 [==============================] - 0s 5us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 943/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 944/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 945/1000\n",
      "20533/20533 [==============================] - ETA: 0s - loss: 0.4286 - accuracy: 0.79 - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 946/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 947/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 948/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 949/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 950/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 951/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 952/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 953/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 954/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 955/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 956/1000\n",
      "20533/20533 [==============================] - 0s 7us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 957/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 958/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 959/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 960/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 961/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 962/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 963/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 964/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 965/1000\n",
      "20533/20533 [==============================] - ETA: 0s - loss: 0.4338 - accuracy: 0.79 - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 966/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 967/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 968/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 969/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 970/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 971/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 972/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 973/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 974/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 975/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 976/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 977/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 978/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 979/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 980/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 981/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 982/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 983/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 984/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 985/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 986/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 987/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 988/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 989/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 990/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 991/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 992/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 993/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 994/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 995/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 996/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 997/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 998/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 999/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n",
      "Epoch 1000/1000\n",
      "20533/20533 [==============================] - 0s 6us/step - loss: 0.4322 - accuracy: 0.7975 - val_loss: 0.4278 - val_accuracy: 0.8021\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train1, y_u_train1,validation_data = (X_test1,y_u_test1), epochs=1000, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11702/11702 [==============================] - 0s 20us/step\n",
      "[0.42490938282424495, 0.8021705746650696]\n",
      "[0 0 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_u_test,verbose=1)\n",
    "\n",
    "print(score)\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(history.history)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss']) \n",
    "plt.title('Model loss') \n",
    "plt.ylabel('Loss') \n",
    "plt.xlabel('Epoch') \n",
    "plt.legend(['Train', 'Test'], loc='upper left') \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.2 s ± 2.86 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "5134\n",
      "2667\n"
     ]
    }
   ],
   "source": [
    "%t classifier.fit(X_train1 , y_train1)\n",
    "\n",
    "#Testing the classification on the test sample\n",
    "Y_predict_rf1 = classifier.predict(X_test1)\n",
    "\n",
    "print(len(y_test1))\n",
    "print(len(Y_predict_rf1[Y_predict_rf1 == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.78      0.80      2563\n",
      "         1.0       0.79      0.82      0.80      2571\n",
      "\n",
      "    accuracy                           0.80      5134\n",
      "   macro avg       0.80      0.80      0.80      5134\n",
      "weighted avg       0.80      0.80      0.80      5134\n",
      "\n",
      "Accuracy is: 80.31105793881387\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf_report_rf1 = classification_report(y_test1, Y_predict_rf1)\n",
    "print(clf_report_rf1)\n",
    "a1 = accuracy_score(pred,test)\n",
    "print('Accuracy is:', a1*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
